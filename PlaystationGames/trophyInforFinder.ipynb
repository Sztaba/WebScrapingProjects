{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting URLs for L.A. Noire\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "429 Client Error: Too Many Requests for url: https://www.google.com/sorry/index?continue=https://www.google.com/search%3Fq%3DL.A.%252BNoire%252BPSNProfiles%26num%3D10%26hl%3Den%26start%3D0&hl=en&q=EhAqAqMaokIIgDElIV9FhGz3GLbUqbEGIjDBU6DKtFFJvPV46lRa-Sq7pug3ODPqaySlpAYXexVOvOfhm0OAqIwxITVJJgvG2-EyAXJaAUM",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m searchResults \u001b[38;5;241m=\u001b[39m search(query, num_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, sleep_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     18\u001b[0m urls \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m searchResults:\n\u001b[0;32m     20\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpsnprofiles.com/trophies/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m j \u001b[38;5;129;01mand\u001b[39;00m j\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m     21\u001b[0m \t\turls\u001b[38;5;241m.\u001b[39mappend(j)\n",
      "File \u001b[1;32mc:\\Users\\huber\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\googlesearch\\__init__.py:54\u001b[0m, in \u001b[0;36msearch\u001b[1;34m(term, num_results, lang, proxy, advanced, sleep_interval, timeout)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\huber\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\googlesearch\\__init__.py:23\u001b[0m, in \u001b[0;36m_req\u001b[1;34m(term, results, lang, start, proxies, timeout)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\huber\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1016\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1017\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1018\u001b[0m     )\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 429 Client Error: Too Many Requests for url: https://www.google.com/sorry/index?continue=https://www.google.com/search%3Fq%3DL.A.%252BNoire%252BPSNProfiles%26num%3D10%26hl%3Den%26start%3D0&hl=en&q=EhAqAqMaokIIgDElIV9FhGz3GLbUqbEGIjDBU6DKtFFJvPV46lRa-Sq7pug3ODPqaySlpAYXexVOvOfhm0OAqIwxITVJJgvG2-EyAXJaAUM"
     ]
    }
   ],
   "source": [
    "from googlesearch import search\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# load json data from operaBookmarksExtractor.ipynb\n",
    "with open('Data/games.json', 'r') as f:\n",
    "    games_dict = json.load(f)\n",
    "\n",
    "psnp_urls = []\n",
    "i = 0\n",
    "# find all PSNProfiles trophy list urls for each game (there can be many urls as each game could be released more than once on different system)\n",
    "for g in games_dict['title']:\n",
    "\tprint(\"Getting URLs for\", g)\n",
    "\tquery = g + \" PSNProfiles\"\n",
    "\tsearchResults = search(query, num_results=8, sleep_interval=5)\n",
    "\turls = []\n",
    "\tfor j in searchResults:\n",
    "\t\tif \"psnprofiles.com/trophies/\" in j and j.count('/') == 4:\n",
    "\t\t\turls.append(j)\n",
    "\tpsnp_urls.append(urls)\n",
    "\ti += 1\n",
    "\tif i == 5:\n",
    "\t\tbreak\n",
    "games_dict[\"psnprofilesTrophyList\"] = psnp_urls\n",
    "\n",
    "with open('Data/games_with_urls.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(games_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'psnprofilesTrophyList'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhtml\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(games_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m])):\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgames_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpsnprofilesTrophyList\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[i]:\n\u001b[0;32m      5\u001b[0m         response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://webcache.googleusercontent.com/search?q=cache:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m u \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m&vwsrc=1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m         htmlCode \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39munescape(response\u001b[38;5;241m.\u001b[39mtext)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'psnprofilesTrophyList'"
     ]
    }
   ],
   "source": [
    "import html\n",
    "\n",
    "platinum_percents = []\n",
    "for i in range(len(games_dict[\"title\"])):\n",
    "    platsForGame = []\n",
    "    for u in games_dict[\"psnprofilesTrophyList\"][i]:\n",
    "        response = requests.get(\"http://webcache.googleusercontent.com/search?q=cache:\" + u + \"&vwsrc=1\")\n",
    "        htmlCode = html.unescape(response.text)\n",
    "        soup = BeautifulSoup(htmlCode, 'html.parser')\n",
    "        stats = soup.find('div', class_='stats flex')\n",
    "        for s in stats.find_all('span', class_='stat grow'):\n",
    "            if s.find('span').text == 'Platinum Achievers':\n",
    "                proc = s.text\n",
    "        match = re.search(r'\\d\\d\\.\\d\\d', proc).group()\n",
    "        platsForGame.append(float(match))\n",
    "    platinum_percents.append(platsForGame)\n",
    "    \n",
    "games_dict['platinumPercents'] = platinum_percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.08\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\"http://webcache.googleusercontent.com/search?q=cache:https://psnprofiles.com/trophies/8956-borderlands&vwsrc=1\")\n",
    "htmlCode = html.unescape(response.text)\n",
    "soup = BeautifulSoup(htmlCode, 'html.parser')\n",
    "stats = soup.find('div', class_='stats flex')\n",
    "for s in stats.find_all('span', class_='stat grow'):\n",
    "    if s.find('span').text == 'Platinum Achievers':\n",
    "        proc = s.text\n",
    "# match = re.search(r'\\(.*\\)', proc).group()\n",
    "match = re.search(r'\\d\\d\\.\\d\\d', proc).group()\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "\n",
    "with open(\"Data/temp2.html\", 'w') as f:\n",
    "    f.write(response.text)\n",
    "# print(response.text)\n",
    "\n",
    "r = html.unescape(response.text)\n",
    "print(r)\n",
    "with open(\"Data/temp2.html\", 'w', encoding='utf-8') as f:\n",
    "    f.write(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
