{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import openpyxl\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of last page avalaible\n",
    "def get_last_news_page() -> int:\n",
    "    url = \"https://www.gamespot.com/news/\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    btn = soup.find_all('a', class_='btn', recursive=True)\n",
    "    pages = []\n",
    "    for b in btn:\n",
    "        try:\n",
    "            p = int(b.text)\n",
    "            pages.append(p)\n",
    "        except:\n",
    "            continue\n",
    "    last_page = max(pages)\n",
    "    return last_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get news between news_min and news_max. Returns dictionary with info about news (titles, links, dates)\n",
    "def get_gamespot_news(last_page: int, news_min: int, news_max: int, display: bool = False) -> dict:    \n",
    "    titles, links, dates, pages = [],[],[],[]\n",
    "    url = \"https://www.gamespot.com/news/\"\n",
    "    sum_news = 0\n",
    "    for i in range(last_page):\n",
    "        try:\n",
    "            response = requests.get(url + \"?page=\" + str(last_page - i))\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            news = soup.find_all('div', class_=\"card-item__content\")\n",
    "            news = news[::-1]\n",
    "            if (len(news) + sum_news) < news_min:\n",
    "                sum_news += len(news)\n",
    "                continue\n",
    "            elif (len(news) + 120 + sum_news) < sum_news:\n",
    "                sum_news += len(news) + 120\n",
    "                i += 2\n",
    "                continue\n",
    "            for j in range(len(news)):\n",
    "                if news_min <= sum_news + 1 <= news_max:\n",
    "                    a = news[j].find('a', class_='card-item__link')\n",
    "                    title = a.text\n",
    "                    link = \"https://www.gamespot.com\" + str(a.get('href'))\n",
    "                    date = news[j].find('time').get('datetime')\n",
    "                    titles.append(title)\n",
    "                    links.append(link)\n",
    "                    dates.append(date)\n",
    "                    pages.append(last_page - i)\n",
    "                    if display == True:\n",
    "                        if (sum_news - news_min + 1) % 100 == 0 and (sum_news - news_min + 1) != 0:\n",
    "                            loaded = (sum_news - news_min + 1)\n",
    "                            percent = round((100 * loaded)/(news_max - news_min + 1), 2)\n",
    "                            print(loaded, \"news loaded ( \" + str(percent) + \"% )\")\n",
    "                if sum_news > news_max:\n",
    "                    final_dict = {}\n",
    "                    final_dict['titles'] = titles\n",
    "                    final_dict['links'] = links\n",
    "                    final_dict['dates'] = dates\n",
    "                    return final_dict\n",
    "                \n",
    "                sum_news += 1\n",
    "        except:\n",
    "            print(\"Error occured\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate GameSpot news <from_value, to_value> where value 1 means first article ever. Multiplier is used to generate the same number of news in a sequence.\n",
    "def generate_gamespot_news(from_value: int, to_value: int, multiplier: int = 1) -> None:\n",
    "    folder_name = datetime.now()\n",
    "    folder_name = folder_name.strftime('%Y_%m_%d %H-%M-%S')\n",
    "    os.makedirs(\"Data/\" + folder_name, exist_ok=True)\n",
    "    last_page = get_last_news_page()\n",
    "    for i in range(multiplier):\n",
    "        l = from_value + (to_value * i)\n",
    "        r = to_value + (to_value * i)\n",
    "        dict_news = get_gamespot_news(last_page, l, r, True)\n",
    "        df = pd.DataFrame(dict_news)\n",
    "        df.to_csv(\"Data/\" + folder_name + \"/news\" + str(l) + '-' + str(r) + \".csv\", index=False)\n",
    "        print(\"news\", str(l) + '-' + str(r), \"saved\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MS Excel file for given folder name which were generated before. Every portion of news (if multiplier = 1 then there is only one portion) has it's own sheet\n",
    "def create_excel_file(target_folder_name: str) -> None:\n",
    "    try:\n",
    "        file_names = os.listdir(\"Data/\" + target_folder_name)  \n",
    "    except FileNotFoundError:\n",
    "        print(\"No such directory\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(\"Data/Sheets\", exist_ok=True)\n",
    "    filenames_values = []\n",
    "    csv_file_names = []\n",
    "\n",
    "    for f in file_names:\n",
    "        pattern = r'news(\\d+)-(\\d+)\\.csv'\n",
    "        match = re.match(pattern, f)\n",
    "        if match:\n",
    "            value1 = int(match.group(1))\n",
    "            value2 = int(match.group(2))\n",
    "            filenames_values.append(value1)\n",
    "            filenames_values.append(value2)\n",
    "            csv_file_names.append(f)\n",
    "\n",
    "    if not csv_file_names:\n",
    "        print(\"No matching CSV files found.\")\n",
    "        return\n",
    "\n",
    "    excel_path = f\"Data/Sheets/NewsSheet{target_folder_name} {min(filenames_values)}-{max(filenames_values)}.xlsx\"\n",
    "    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "        for f in csv_file_names:\n",
    "            df = pd.read_csv(f\"Data/{target_folder_name}/{f}\")\n",
    "            df['rating'] = ''  # Add the 'rating' column without any default value (empty)\n",
    "            sheet_name = f.replace(\".csv\", \"\")\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "            # Formatting with openpyxl\n",
    "            workbook = writer.book\n",
    "            worksheet = writer.sheets[sheet_name]\n",
    "            for row in worksheet.iter_rows():\n",
    "                for cell in row:\n",
    "                    cell.alignment = openpyxl.styles.Alignment(wrap_text=True)\n",
    "                    # Convert URL text to hyperlinks if they look like URLs\n",
    "                    if isinstance(cell.value, str) and (cell.value.startswith('http://') or cell.value.startswith('https://')):\n",
    "                        cell.hyperlink = cell.value\n",
    "\n",
    "            for col in worksheet.columns:\n",
    "                max_length = 0\n",
    "                column = col[0].column_letter\n",
    "                for cell in col:\n",
    "                    try:\n",
    "                        if len(str(cell.value)) > max_length:\n",
    "                            max_length = len(cell.value)\n",
    "                    except:\n",
    "                        pass\n",
    "                adjusted_width = (max_length + 2) * 1.2 \n",
    "                worksheet.column_dimensions[column].width = adjusted_width\n",
    "\n",
    "    print(f\"Excel file created at {excel_path}\")\n",
    "\n",
    "# Example usage\n",
    "create_excel_file(\"ExampleFolder\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_gamespot_news(1, 1000, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = '2024_05_26 20-09-45'\n",
    "create_excel_file(target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
